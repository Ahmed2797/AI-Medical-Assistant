{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dc7ecd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ahmed/CV_ADD_PROJECT/AIEnginear/AI-Medical-Assistant'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e09e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ahmed/CV_ADD_PROJECT/AIEnginear'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f787cb0a",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1iVvTfm3sxA1xmaXbcWHmbcGNJbghi3xn/view?usp=drive_link\n",
    "\n",
    "https://drive.google.com/file/d/10BZvKanGhfBhaB5nSbtFOuFpKD2731IZ/view?usp=sharing\n",
    "\n",
    "https://drive.google.com/file/d/1obGHxfCcPx0tm5rjkcSNbsVK3PH0UYnv/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5367912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gdown 1iVvTfm3sxA1xmaXbcWHmbcGNJbghi3xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc85a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U \\\n",
    "#   langchain \\\n",
    "#   langchain-openai \\\n",
    "#   langchain-community \\\n",
    "#   chromadb \\\n",
    "#   openai \\\n",
    "#   unstructured \\\n",
    "#   \"unstructured[pdf]\" \\\n",
    "#   pillow==10.2.0\\\n",
    "#   pydantic \\\n",
    "#   python-dotenv \\\n",
    "#   pytesseract \\\n",
    "#   opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a89a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import shutil\n",
    "# import streamlit as st\n",
    "from PIL import Image\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# --- CONFIGURATION & DIRECTORIES ---\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "IMAGE_DIR = \"figures\"\n",
    "\n",
    "\n",
    "\n",
    "for folder in [IMAGE_DIR, CHROMA_PATH]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "class MultiModalRAG:\n",
    "    def __init__(self):\n",
    "        # High-reasoning model (Cheap & Fast)\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=\"multirag\",\n",
    "            embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "            persist_directory=CHROMA_PATH\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    def summarize_image(self, image_path):\n",
    "        \"\"\"Standardizes visual data into searchable text.\"\"\"\n",
    "        b64_image = self.encode_image(image_path)\n",
    "        response = self.llm.invoke([\n",
    "            HumanMessage(content=[\n",
    "                {\"type\": \"text\", \"text\": \"Analyze this image from a document. Describe charts, data points, or visual content for a search index.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64_image}\"}}\n",
    "            ])\n",
    "        ])\n",
    "        return response.content\n",
    "\n",
    "    def process_pdf(self, file_path):\n",
    "        \"\"\"Industry-standard partitioning for PDF extraction.\"\"\"\n",
    "        elements = partition_pdf(\n",
    "            filename=file_path,\n",
    "            strategy=\"hi_res\",\n",
    "            extract_images_in_pdf=True,\n",
    "            infer_table_structure=True,\n",
    "            chunking_strategy=\"by_title\",\n",
    "            max_characters=1500,\n",
    "            image_output_dir_path=IMAGE_DIR\n",
    "        )\n",
    "        \n",
    "        for el in elements:\n",
    "            metadata = {\"source\": file_path, \"type\": \"text\"}\n",
    "            if \"Image\" in str(type(el)):\n",
    "                img_path = el.metadata.image_path\n",
    "                content = self.summarize_image(img_path)\n",
    "                metadata.update({\"type\": \"image\", \"image_path\": img_path})\n",
    "            else:\n",
    "                content = el.text\n",
    "            \n",
    "            if content:\n",
    "                self.vectorstore.add_texts(texts=[content], metadatas=[metadata])\n",
    "        \n",
    "        return elements\n",
    "\n",
    "    def query_system_image(self, user_input, is_image=False):\n",
    "        \"\"\"Cross-modal retrieval logic.\"\"\"\n",
    "        search_query = user_input\n",
    "        if is_image:\n",
    "            search_query = self.summarize_image(user_input)\n",
    "        \n",
    "        # Retrieve top matches\n",
    "        docs = self.vectorstore.similarity_search(search_query, k=3)\n",
    "        \n",
    "        # Formulate answer based on context\n",
    "        context_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "        prompt = [\n",
    "            # SystemMessage(content=\"Answer the question using ONLY the provided context. Show expertise and clarity.\"),\n",
    "            # SystemMessage(content=\"Answer based ONLY on the provided context. If an image is relevant, mention it.\"),\n",
    "            SystemMessage(content=\"You are a helpful assistant. Answer the question using ONLY the provided context and if an image is relevant, mention it. If the answer isn't in the context, say you don't know.\"),\n",
    "\n",
    "            HumanMessage(content=f\"Context:\\n{context_text}\\n\\nQuestion: {search_query}\")\n",
    "        ]\n",
    "        answer = self.llm.invoke(prompt).content\n",
    "        return answer, docs\n",
    "\n",
    "\n",
    "    def query_system_all(self, user_input, is_image=False):\n",
    "        \"\"\"\n",
    "        Cross-modal retrieval logic:\n",
    "        - Text query → direct vector search\n",
    "        - Image query → image → text summary → vector search\n",
    "        \"\"\"\n",
    "\n",
    "        # 1️⃣ Decide search query\n",
    "        if is_image:\n",
    "            if not os.path.exists(user_input):\n",
    "                raise ValueError(f\"Image file not found: {user_input}\")\n",
    "\n",
    "            # Convert image → searchable text\n",
    "            search_query = self.summarize_image(user_input)\n",
    "        else:\n",
    "            # Plain text query\n",
    "            search_query = user_input\n",
    "\n",
    "        # 2️⃣ Retrieve relevant chunks\n",
    "        docs = self.vectorstore.similarity_search(search_query, k=3)\n",
    "\n",
    "        # 3️⃣ Build context safely\n",
    "        if not docs:\n",
    "            return \"I don't know. No relevant context was found.\", []\n",
    "\n",
    "        context_text = \"\\n\\n\".join(\n",
    "            [f\"[Chunk {i+1}]\\n{d.page_content}\" for i, d in enumerate(docs)]\n",
    "        )\n",
    "\n",
    "        # 4️⃣ LLM prompt\n",
    "        prompt = [\n",
    "            SystemMessage(\n",
    "                content=(\n",
    "                    \"You are a helpful assistant. \"\n",
    "                    \"Answer the question using ONLY the provided context. \"\n",
    "                    \"If the answer is not in the context, say 'I don't know'. \"\n",
    "                    \"If an image is relevant, mention it.\"\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Context:\\n{context_text}\\n\\nQuestion:\\n{search_query}\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 5️⃣ Generate answer\n",
    "        answer = self.llm.invoke(prompt).content\n",
    "\n",
    "        return answer, docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b4acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "435709d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv\n",
    "OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55894/3542998679.py:25: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  self.vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "rag = MultiModalRAG()\n",
    "elements = rag.process_pdf(file_path='Data/image_table_columns.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melements\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "print(len(elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ec3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'figures/figure-1-6.jpg'\n",
    "answer, docs = rag.query_system_all(user_input=query,is_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16cdf7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image features a bar chart displaying data over a five-year period from 2020 to 2024, with an upward trend indicating growth. The y-axis ranges from 0 to 25, and the bars, colored orange, represent data points for each year, showing consistent increases in values from approximately 5 in 2020 to close to 20 in 2024.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc51d11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'type': 'text', 'source': 'Data/image_table_columns.pdf'}, page_content='>\\n\\nFINANGI AL\\n\\nSTATEMENT\\n\\nExplore our financial performance through balance sheets, income, and cash flow statements.\\n\\nDELAITTE\\n\\nStartupAI boasts an impressive return on investment (ROI), demonstrating its financial acumen and ability to generate substantial profits for its stakeholders through strategic decisions and operational excellence.\\n\\nGROSS INCOME 22,000,000 $ TOTAL EXPENSES 2.000,000 $ TAXES 5,000.000 $ NET INCOME 15,000,000 $\\n\\n33% ROI\\n\\nStartupAI has achieved a remarkable $22 million in sales, showcasing its market dominance and strong customer appeal.\\n\\n25 20 15 10 5 0\\n\\n2020 2021 2022 2023 2024\\n\\nwww.startupAI.com\\n\\n+123-456-7890')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce121a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahmed/CV_ADD_PROJECT/AIEnginear/chroma_db\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './chroma_db'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m CHROMA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(CHROMA_PATH))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHROMA_PATH\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './chroma_db'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "print(os.path.abspath(CHROMA_PATH))\n",
    "print(os.listdir(CHROMA_PATH))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f788235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(CHROMA_PATH, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c7b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ed63d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Database error: error returned from database: (code: 1) no such table: tenants",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rag \u001b[38;5;241m=\u001b[39m \u001b[43mMultiModalRAG\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m elements \u001b[38;5;241m=\u001b[39m rag\u001b[38;5;241m.\u001b[39mprocess_pdf(file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/image_table_columns.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 25\u001b[0m, in \u001b[0;36mMultiModalRAG.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# High-reasoning model (Cheap & Fast)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultirag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-embedding-3-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHROMA_PATH\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:239\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     emit_warning()\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:122\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m    120\u001b[0m         _client_settings \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSettings()\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m _client_settings\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_client_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persist_directory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    124\u001b[0m         _client_settings\u001b[38;5;241m.\u001b[39mpersist_directory \u001b[38;5;129;01mor\u001b[39;00m persist_directory\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;241m=\u001b[39m embedding_function\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/chromadb/__init__.py:433\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(settings, tenant, database)\u001b[0m\n\u001b[1;32m    430\u001b[0m tenant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[1;32m    431\u001b[0m database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/chromadb/api/client.py:101\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, tenant, database, settings)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Create an admin client for verifying that databases and tenants exist\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_admin_client \u001b[38;5;241m=\u001b[39m AdminClient\u001b[38;5;241m.\u001b[39mfrom_system(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_system)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tenant_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_client_start_event()\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/chromadb/api/client.py:485\u001b[0m, in \u001b[0;36mClient._validate_tenant_database\u001b[0;34m(self, tenant, database)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Propagate ChromaErrors\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChromaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not connect to tenant \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtenant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Are you sure it exists?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/chromadb/api/client.py:478\u001b[0m, in \u001b[0;36mClient._validate_tenant_database\u001b[0;34m(self, tenant, database)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_tenant_database\u001b[39m(\u001b[38;5;28mself\u001b[39m, tenant: \u001b[38;5;28mstr\u001b[39m, database: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_admin_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tenant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mConnectError:\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not connect to a Chroma server. Are you sure it is running?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/chromadb/api/client.py:535\u001b[0m, in \u001b[0;36mAdminClient.get_tenant\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_tenant\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tenant:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tenant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.10/site-packages/chromadb/api/rust.py:174\u001b[0m, in \u001b[0;36mRustBindingsAPI.get_tenant\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_tenant\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tenant:\n\u001b[0;32m--> 174\u001b[0m     tenant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tenant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tenant(name\u001b[38;5;241m=\u001b[39mtenant\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[0;31mInternalError\u001b[0m: Database error: error returned from database: (code: 1) no such table: tenants"
     ]
    }
   ],
   "source": [
    "rag = MultiModalRAG()\n",
    "elements = rag.process_pdf(file_path='Data/image_table_columns.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a64d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
